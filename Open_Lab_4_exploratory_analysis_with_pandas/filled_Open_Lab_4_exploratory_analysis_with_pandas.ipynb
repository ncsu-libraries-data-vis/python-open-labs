{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Open Labs: Exploratory analysis with pandas\n",
    "\n",
    "## Setup\n",
    "With this Google Colaboratory (Colab) notebook open, click the \"Copy to Drive\" button that appears in the menu bar. The notebook will then be attached to your own user account, so you can edit it in any way you like -- you can even take notes directly in the notebook.\n",
    "\n",
    "## Instructors\n",
    "- Walt Gurley\n",
    "- Claire Cahoon\n",
    "\n",
    "## Open Labs agenda\n",
    "\n",
    "1.   **Guided activity**: One of the instructors will share their screen to work through the guided activity and teach concepts along the way.\n",
    "\n",
    "2.   **Open lab time**: After the guided portion of the Open Lab, the rest of the time is for you to ask questions, work collaboratively, or have self-guided practice time. You will have access to instructors and peers for questions and support.\n",
    "\n",
    "Breakout rooms will be available if you would like to work in small groups. If you have trouble joining a room, ask in the chat to be moved into a room.\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "By the end of the workshop today, we hope you'll...\n",
    "TODO\n",
    "\n",
    "Series announcement: In this lab we will cover common exploratory analysis methods such as calculating summary statistics and aggregating and grouping data using pandas. \n",
    "\n",
    "## Today's Topics\n",
    "- TODO\n",
    "- Exploratory analysis\n",
    "- Counts by nationality or gender\n",
    "- Comparing measurements\n",
    "- Dates over time (add in factors like nationality or gender)\n",
    "\n",
    "## Questions during the workshop\n",
    "\n",
    "Please feel free to ask questions throughout the workshop.\n",
    "\n",
    "We have a second instructor who will available during the workshop. They will answer as able, and will collect questions with answers that might help everyone to be answered at the end of the workshop.\n",
    "\n",
    "The open lab time is when you will be able to ask more questions and work together on the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Jupyter Notebooks and Google Colaboratory\n",
    "\n",
    "Jupyter notebooks are a way to write and run Python code in an interactive way. They're quickly becoming a standard way of putting together data, code, and written explanations or visualizations into a single document and sharing that. There are a lot of ways that you can run Jupyter notebooks, including just locally on your computer, but we've decided to use Google's Colaboratory notebook platform for this workshop.  Colaboratory is “a Google research project created to help disseminate machine learning education and research.”  If you would like to know more about Colaboratory in general, you can visit the [Welcome Notebook](https://colab.research.google.com/notebooks/welcome.ipynb).\n",
    "\n",
    "Using the Google Colaboratory platform allows us to focus on learning and writing Python in the workshop rather than on setting up Python, which can sometimes take a bit of extra work depending on platforms, operating systems, and other installed applications. If you'd like to install a Python distribution locally, though, we're happy to help. Feel free to [get help from our graduate consultants](https://www.lib.ncsu.edu/dxl) or [schedule an appointment with Libraries staff](https://go.ncsu.edu/dvs-request)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided Instruction\n",
    "In this section, we will work through examples using data from the [Museum of Modern Art (MoMA) research dataset](https://github.com/MuseumofModernArt/collection) containing records of all of the works that have been cataloged in the database of the MoMA collection.\n",
    "\n",
    "We have split the dataset into several different subsections (paintings, sculptures, photographs, and artist information) and file types to use in activities. We will be referencing the data that we have prepared in our [Github repository for teaching datasets](https://github.com/ncsu-libraries-data-vis/teaching-datasets/tree/main/moma_data).\n",
    "\n",
    "### Exploratory analysis of the dataset\n",
    "\n",
    "After observing and cleaning our dataset, it is now easier to conduct analyses on our data. We will conduct some numerical and visual analyses that will help us explore questions such as:\n",
    "\n",
    "- How many unique species have been identified in the data set?\n",
    "- Which species are struck the most?\n",
    "- How have number of strikes changed over time?\n",
    "- Are there times of the year when most strikes occur?\n",
    "- How frequently are land-based animals involved?\n",
    "\n",
    "We can do this by calculating summaries of rows and columns, grouping data, and visualizing the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas library as pd (callable in our code as pd)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ConstituentID</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>ArtistBio</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BeginDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Wiki QID</th>\n",
       "      <th>ULAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Robert Arneson</td>\n",
       "      <td>American, 1930–1992</td>\n",
       "      <td>American</td>\n",
       "      <td>Male</td>\n",
       "      <td>1930</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Doroteo Arnaiz</td>\n",
       "      <td>Spanish, born 1936</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Male</td>\n",
       "      <td>1936</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bill Arnold</td>\n",
       "      <td>American, born 1941</td>\n",
       "      <td>American</td>\n",
       "      <td>Male</td>\n",
       "      <td>1941</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Charles Arnoldi</td>\n",
       "      <td>American, born 1946</td>\n",
       "      <td>American</td>\n",
       "      <td>Male</td>\n",
       "      <td>1946</td>\n",
       "      <td>0</td>\n",
       "      <td>Q1063584</td>\n",
       "      <td>500027998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Per Arnoldi</td>\n",
       "      <td>Danish, born 1941</td>\n",
       "      <td>Danish</td>\n",
       "      <td>Male</td>\n",
       "      <td>1941</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ConstituentID      DisplayName            ArtistBio Nationality Gender  \\\n",
       "0              1   Robert Arneson  American, 1930–1992    American   Male   \n",
       "1              2   Doroteo Arnaiz   Spanish, born 1936     Spanish   Male   \n",
       "2              3      Bill Arnold  American, born 1941    American   Male   \n",
       "3              4  Charles Arnoldi  American, born 1946    American   Male   \n",
       "4              5      Per Arnoldi    Danish, born 1941      Danish   Male   \n",
       "\n",
       "   BeginDate  EndDate  Wiki QID         ULAN  \n",
       "0       1930     1992       NaN          NaN  \n",
       "1       1936        0       NaN          NaN  \n",
       "2       1941        0       NaN          NaN  \n",
       "3       1946        0  Q1063584  500027998.0  \n",
       "4       1941        0       NaN          NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data from a csv file\n",
    "# This dataset was cleaned based on methods from previous workshops\n",
    "csv_file_url = 'https://raw.githubusercontent.com/ncsu-libraries-data-vis/teaching-datasets/main/moma_data/moma_artists.csv'\n",
    "# TODO - change this to the cleaned dataset\n",
    "\n",
    "art = pd.read_csv(csv_file_url)\n",
    "\n",
    "# Print out the first five columns of the dataset\n",
    "art.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation Methods\n",
    "\n",
    "There are several methods that can be used to calculate aggregated values from the dataset, such as the number of unique values, unique value counts, minimum, maximum, and average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unique\n",
    "\n",
    "\n",
    "We can use the `unique()` method on the \"Artist\" column to create an array of unique artist names. \n",
    "\n",
    "The length of this array will provide the number of unique artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Artist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Artist'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-5eef39e32e00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create a list of the unique artists with unique()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0munique_artists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mart\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Artist'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Print out the unique artists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0munique_artists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Artist'"
     ]
    }
   ],
   "source": [
    "# Create a list of the unique artists with unique()\n",
    "unique_artists = art['Artist'].unique()\n",
    "\n",
    "# Print out the unique artists\n",
    "unique_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13685"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the length of the new array using len()\n",
    "# How many unique species are there?\n",
    "len(unique_artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value counts\n",
    "\n",
    "Value counts show how many instances there are of each unique entry in a column. Here, we are interested in seeing the gender breakdown for works of art, or how many pieces of art were created by different genders. This might be interesting as part of an equity audit to make sure the museum is representing all different kinds of artists and artwork.\n",
    "\n",
    "We will specify the `Gender` column in our dataset and call the method `value_counts()`. This will return a Series with an index label of each unique gender and a value corresponding to the count of that gender identity in the `Gender` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Female        2300\n",
       "Male          9762\n",
       "Non-Binary       2\n",
       "Non-binary       1\n",
       "female           1\n",
       "male            15\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the occurance of unique values on the column 'Gender'\n",
    "gender = art['Gender'].value_counts()\n",
    "\n",
    "# Sort the Series by its index using sort_index(), to help view yearly trend\n",
    "gender.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimum, maximum, average...\n",
    "\n",
    "We can also calculate aggregates like the minimum, maximum, and mean of values in a DataFrame or Series. Here are a few examples:\n",
    "\n",
    "- `mean()` to find the average of a range\n",
    "- `min()` to find the smallest value\n",
    "- `max()` to find the largest value\n",
    "- `sum()` to sum the values of a range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AccessionNumber                      1.1929\n",
       "Classification               (not assigned)\n",
       "Department            Architecture & Design\n",
       "Cataloged                                 N\n",
       "ObjectID                                  2\n",
       "Circumference (cm)                      9.9\n",
       "Depth (cm)                                0\n",
       "Diameter (cm)                         0.635\n",
       "Height (cm)                               0\n",
       "Length (cm)                               0\n",
       "Weight (kg)                            0.09\n",
       "Width (cm)                                0\n",
       "Seat Height (cm)                        NaN\n",
       "Duration (sec.)                           0\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the minimum values for each column\n",
    "# Note the minimum values for columns not containing numbers (e.g., the minimum\n",
    "# for strings is alphabetical order, with uppercase characters preceeding\n",
    "# lowercase characters - \"B\" comes before \"a\")\n",
    "art.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.45612361859556"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the average height for all pieces of art in this collection\n",
    "art['Height (cm)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean     23.094845\n",
       "min       0.635000\n",
       "max     914.400000\n",
       "Name: Diameter (cm), dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the minimum, maximum, and average diameter for art in this collection\n",
    "art['Diameter (cm)'].agg(['mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group values using groupby\n",
    "\n",
    "We may be interested in seeing our data in groups. For example, what does the data look like if we group by nationality and find the count of each column? Which nationalities are represented in this collection and how frequently?\n",
    "\n",
    "We can do this by calling `groupby()` on our dataset and passing in the column we would like to group by. We will group our data by the column `Nationality`, find the count of each column in the grouped data, and sort by the `COST_REPAIRS_INFL_ADJ` column to see which month has the highest average cost. TODO - sort by?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-d8ec535fd5f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Group the dataset by \"Nationality\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mart_by_nationality\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# TODO - Potentially groupby the year of the artwork and then find gender or nationality counts?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   6509\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6511\u001b[1;33m         return DataFrameGroupBy(\n\u001b[0m\u001b[0;32m   6512\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6513\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[0;32m    526\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    779\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 781\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    782\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[1;31m# Add key to exclusions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date'"
     ]
    }
   ],
   "source": [
    "# Group the dataset by \"Nationality\"\n",
    "art_by_nationality = art.groupby('Date')\n",
    "\n",
    "# TODO - Potentially groupby the year of the artwork and then find gender or nationality counts?\n",
    "\n",
    "# This creates a groupby object that contains information about the groups\n",
    "type(art_by_nationality)\n",
    "\n",
    "# Find the mean of the grouped data, then sort by \"COST_REPAIRS_INFL_ADJ\"\n",
    "art_by_nationality.mean()\n",
    "\n",
    "#.sort_values('COST_REPAIRS_INFL_ADJ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use `groupby()` to group data by multiple variables. We will create a hierarchical grouping of `INCIDENT_MONTH` and then `PRECIPITATION` to see the counts of different types of precipitation in each month using the `size()` groupby method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the unique values in the \"PRECIPITATION\" column\n",
    "wl_strikes['PRECIPITATION'].unique()\n",
    "\n",
    "# Group the data by month and then precipitation and get the count of each type\n",
    "# of precipitation during each month using size()\n",
    "wl_strikes.groupby(['INCIDENT_MONTH', 'PRECIPITATION']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open work time\n",
    "You can use this time to ask questions, collaborate, or work on the following activities (on your own or in a group). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Aggregation\n",
    "\n",
    "**TODO make these about the photographs dataset or similar\n",
    "\n",
    "Find the average, minimum, and maximum from the column 'SPEED'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get general statistics of altitude when strike occured\n",
    "wl_strikes['SPEED'].agg(['mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Grouping Values\n",
    "\n",
    "Find how expensive repairs (the data in column `'COST_REPAIRS_INFL_ADJ'`) were at each time of day (dawn, dusk, day, and night). Group the data using `TIME_OF_DAY`, then show a table with the average cost of repairs for each time of day, sorted from least expensive to most expensive.\n",
    "\n",
    "\n",
    "\n",
    "> Bonus discussion question: does showing the data this way tell the whole story? What other factors could affect these numbers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable that stores clean_data grouped by TIME_OF_DAY\n",
    "data_by_month = wl_strikes.groupby('TIME_OF_DAY')\n",
    "\n",
    "# Find the mean of the data based on the cost of repairs\n",
    "data_by_month = data_by_month.mean()\n",
    "\n",
    "#View the data, sorted by least to most expensive\n",
    "data_by_month['COST_REPAIRS_INFL_ADJ'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Calculate strike totals by month\n",
    "\n",
    "We're considering if there might be a relationship between the number of strikes and bird migration occurance (March-April and August-November -- see [Bird Migration and Areas With Sensitive Fauna](https://www.faa.gov/air_traffic/publications/atpubs/aip_html/part2_enr_section_5.6.html)). Find the total strikes by month to observe any patterns that might occur at the temporal level of month by creating a bar chart of total strikes by month.\n",
    "\n",
    "\n",
    "\n",
    "> Hint: To rotate a chart, there is a keyword that you can add to the `plot()` method. `rot` specifies the rotation of the x-axis tick labels (0.5 = 90 degrees rotation). Example: `your_data.plot(kind='bar', rot=.5)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of strikes that occured during a specific month\n",
    "strikes_by_month = wl_strikes['INCIDENT_MONTH'].value_counts()\n",
    "\n",
    "# Sort the new Series by the index values, the month number\n",
    "strikes_by_month = strikes_by_month.sort_index()\n",
    "\n",
    "# Create a bar chart with the data, rotate the x-axis tick labels by 90 degrees\n",
    "strikes_by_month.plot(kind='bar', rot=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further resources\n",
    "\n",
    "### Filled version of this notebook\n",
    "\n",
    "[Python Open Labs Week 1 filled notebook](https://colab.research.google.com/github/ncsu-libraries-data-vis/python-open-labs/blob/main/Open_Lab_1_reading_exploring_and_writing_data_with_pandas/filled_Open_Lab_1_reading_exploring_and_writing_data_with_pandas.ipynb) - a version of this notebook with all code filled in for the guided activity and exercises. TODO\n",
    "### Learning resources\n",
    "\n",
    "- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/index.html) - a free, online version of Jake VanderPlas' introduction to data science with Python, includes a chapter on data manipulation with pandas.\n",
    "- [Python Programming for Data Science](https://www.tomasbeuzen.com/python-programming-for-data-science/README.html) - a website providing a great overview of conducting data science with Python including pandas.\n",
    "- [Real Python](https://realpython.com/) contains a lot of different tutorials at different levels\n",
    "- [LinkedIn Learning](https://www.lynda.com/Python-training-tutorials/415-0.html) is free with NC State accounts and contains several video series for learning Python\n",
    "- [Dataquest](https://www.dataquest.io/) is a free then paid series of courses with an emphasis on data science\n",
    "\n",
    "### Finding help with pandas\n",
    "\n",
    "The [Pandas website](https://pandas.pydata.org/) and [online documentation](http://pandas.pydata.org/pandas-docs/stable/) are useful resources, and of course the indispensible [Stack Overflow has a \"pandas\" tag](https://stackoverflow.com/questions/tagged/pandas).  There is also a (much younger, much smaller) [sister site dedicated to Data Science questions that has a \"pandas\" tag](https://datascience.stackexchange.com/questions/tagged/pandas) too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Survey\n",
    "Please, spend 1 minute answering these questions that help improve future workshops.\n",
    "\n",
    "https://go.ncsu.edu/dvs-eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "\n",
    "This workshop was created by Claire Cahoon and Walt Gurley, adapted from previous workshop materials by Scott Bailey and Simon Wiles, of Stanford Libraries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
