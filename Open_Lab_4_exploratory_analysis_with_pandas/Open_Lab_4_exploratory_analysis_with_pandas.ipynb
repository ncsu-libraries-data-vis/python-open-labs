{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Open Labs: Exploratory analysis with pandas\n",
    "\n",
    "## Setup\n",
    "With this Google Colaboratory (Colab) notebook open, click the \"Copy to Drive\" button that appears in the menu bar. The notebook will then be attached to your own user account, so you can edit it in any way you like -- you can even take notes directly in the notebook.\n",
    "\n",
    "## Instructors\n",
    "- Walt Gurley\n",
    "- Claire Cahoon\n",
    "\n",
    "## Open Labs agenda\n",
    "\n",
    "1.   **Guided activity**: One of the instructors will share their screen to work through the guided activity and teach concepts along the way.\n",
    "\n",
    "2.   **Open lab time**: After the guided portion of the Open Lab, the rest of the time is for you to ask questions, work collaboratively, or have self-guided practice time. You will have access to instructors and peers for questions and support.\n",
    "\n",
    "Breakout rooms will be available if you would like to work in small groups. If you have trouble joining a room, ask in the chat to be moved into a room.\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "By the end of the workshop today, we hope you'll be able to explore datasets using aggregation methods and grouping.\n",
    "\n",
    "## Today's Topics\n",
    "- Exploratory analysis\n",
    "- Unique values\n",
    "- Value counts\n",
    "- Minimum, maximum, and average\n",
    "- Grouping using `groupby()`\n",
    "\n",
    "## Questions during the workshop\n",
    "\n",
    "Please feel free to ask questions throughout the workshop.\n",
    "\n",
    "We have a second instructor who will available during the workshop. They will answer as able, and will collect questions with answers that might help everyone to be answered at the end of the workshop.\n",
    "\n",
    "The open lab time is when you will be able to ask more questions and work together on the exercises.\n",
    "\n",
    "## Using Jupyter Notebooks and Google Colaboratory\n",
    "\n",
    "Google Colab notebooks are a way to write and run Python code in an interactive way. If you would like to know more about Colaboratory and how to use notebooks, you can visit the [Welcome Notebook](https://colab.research.google.com/notebooks/welcome.ipynb).\n",
    "\n",
    "If you'd like to install a Python distribution locally, we're happy to help. Feel free to [get help from our graduate consultants](https://www.lib.ncsu.edu/dxl) or [schedule an appointment with Libraries staff](https://go.ncsu.edu/dvs-request)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided Instruction\n",
    "In this section, we will work through examples using data from the [Museum of Modern Art (MoMA) research dataset](https://github.com/MuseumofModernArt/collection) containing records of all of the works that have been cataloged in the database of the MoMA collection.\n",
    "\n",
    "We have prepared a dataset that consists of a subset of MoMA artworks classified as paintings and their associated artist information to use in the following activities. We will be referencing the data that we have prepared in our [Github repository for teaching datasets](https://github.com/ncsu-libraries-data-vis/teaching-datasets/tree/main/moma_data).\n",
    "\n",
    "### Exploratory analysis of the dataset\n",
    "\n",
    "Exploratory analysis is a way to explore or observe our data so that we understand it better and can decide which assessments we want to conduct. After learning how to manipulate and clean data, we can start to analyze it. We can explore questions like:\n",
    "\n",
    "- How many different artists are represented in the MoMA collection?\n",
    "- Which departments have the most works of art?\n",
    "- What is the distribution of genders in the MoMA collection? Are some genders better represented in certain departments?\n",
    "- What nationalities are represented in the MoMA collection (and how is that data collected)? Have the areas most commonly represented changed over time?\n",
    "\n",
    "By exploring the data through questions like these, we can find areas of interest for analysis, flaws in the data, or types of data that still need to be collected.\n",
    "\n",
    "We can do this by calculating summaries of rows and columns, identifying specific values, and grouping data. Next week we will continue with visualizing the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas library as pd (callable in our code as pd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the paintings data from a csv file\n",
    "# This dataset was cleaned based on methods from previous workshops\n",
    "paintings_file_url = 'https://raw.githubusercontent.com/ncsu-libraries-data-vis/teaching-datasets/main/moma_data/moma_paintings_final.csv'\n",
    "\n",
    "# Print out the first five columns of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation Methods\n",
    "\n",
    "There are several methods that can be used to calculate aggregated values from the dataset, such as the number of unique values, unique value counts, minimum, maximum, and average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unique\n",
    "`unique()` will return an array containing each unique value in a column of data. That means that duplicate values are only shown once, so it is a useful tool for finding each different reponse in a column of data. If we were interested in how many different responses there were, we could use the `len()` function to find the length of that array.\n",
    "\n",
    "In this example, we use the `unique()` method on the \"Artist\" column to create an array of unique artist names to see each artist that is represented in the collection. The length of this array will provide the number of unique artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the unique artists with unique()\n",
    "\n",
    "# Print out the unique artists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the length of the new array using len()\n",
    "# How many unique species are there?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value counts\n",
    "\n",
    "`.value_counts()` show how many instances there are of each unique entry in a column. It lists each unique value and how many times it appears in a column of data.\n",
    "\n",
    "Here, we are interested in seeing the nationalities of artists in order to figure out which areas of the world are most represented in MoMA.\n",
    "\n",
    "We will specify the `Nationality` column in our Dataframe and call the method `value_counts()`. This will return a Series with an index label of each nationality from the data and a value corresponding to the count of how many times that nationality is lsited in the 'Nationality' column of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurance of unique values on the column 'Nationality'\n",
    "\n",
    "\n",
    "# Sort the Series by the value counts using sort_values()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.value_counts()` can also be a useful exploratory tool. You are able to see how many different categories are in a particular column and if there are areas that you would like to investigate more. \n",
    "\n",
    "For example, our data today only contains artwork that is classified as a \"painting\" in the `Classification` column. However, if we look at the `.value_counts()` to show how many pieces of art are in each department, we can see that they aren't all in the Painting & Sculpture department. Which paintings are housed in other departments and why? Should they be included in our dataset of paintings or not? We can take what we learned in the value counts and continue to filter the data to search for answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the value counts for each department in the paintings data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find out more about why some paintings are housed in the Film department\n",
    "# filter the paintings data by rows where the department is Film\n",
    "# notice that these paintings are all by the same artist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimum, maximum, and average\n",
    "\n",
    "We can also calculate aggregates like the minimum, maximum, and mean of values in a DataFrame or Series. This is primarily useful for numeric values. For strings, aggregates are based on alphabetical order, with uppercase preceeding lowercase (for example, \"B\" would come before \"a\").\n",
    "\n",
    "Here are a few examples:\n",
    "\n",
    "- `mean()` to find the average of a range\n",
    "- `min()` to find the smallest value\n",
    "- `max()` to find the largest value\n",
    "- `sum()` to sum the values of a range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the minimum values for each column with .min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average height for all pieces of art in this collection with .mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the minimum, maximum, and average diameter for art in this collection with .agg()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group values using groupby\n",
    "\n",
    "We may be interested in seeing our data in groups. After the data has been grouped, we can do the same calculations on it as before (mean, min, max). In this example, we group the data based on the column `OilPainting` to see the average of each column based on whether or not it is an oil painting.\n",
    "\n",
    "We can do this by calling `groupby()` on our dataset and passing in the column we would like to group by. We will group our data by the column `OilPainting` and then use the `.mean()` method to find the average of every column based on those groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataset by \"OilPainting\"\n",
    "\n",
    "\n",
    "# This creates a groupby object that contains information about the groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the art based on the listed nationality of the artist\n",
    "\n",
    "\n",
    "# We can also sort the grouped data by any column\n",
    "# Find the mean, then sort by \"Height (cm)\"\n",
    "# ascending=False puts the tallest groups at the top\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use `groupby()` to group data by multiple variables. We will create a hierarchical grouping of `OilPainting` and then `Gender` to see the counts of oil paintings by different genders. We can use `.mean()` to find the average for each of those subcategories, or we can use `.size()` to find counts of each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by OilPainting and then Gender \n",
    "# find the counts of subcategories with .size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open work time\n",
    "You can use this time to ask questions, collaborate, or work on the following activities (on your own or in a group).\n",
    "\n",
    "All of the follow exercises will use a dataset about photos from the MoMA collection. All of the columns are the same as the examples above, but the contents of the rows will be different. You can run the first cell below to read in the dataset as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos_file_url = 'https://raw.githubusercontent.com/ncsu-libraries-data-vis/teaching-datasets/main/moma_data/moma_photographs_final.csv'\n",
    "\n",
    "photos = pd.read_csv(photos_file_url)\n",
    "\n",
    "# Print out the first five columns of the dataset\n",
    "photos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Find value counts\n",
    "\n",
    "1a. How many different mediums were used  to create these photographs? \n",
    "\n",
    "1b. What is the most common medium? Print out a list of how many of each of the mediums is listed with the most common at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Find the average, minimum and maximum\n",
    "\n",
    "Find the average, minimum, and maximum from the column 'Width (cm)'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Grouping Values\n",
    "\n",
    "Find the average year created for each department (Painting & Sculpture, Drawings & Prints, Film, Fluxus Collection, Media & Performance). Group the data using 'Department,' then show a table with the average 'YearCreated' for each department, sorted from oldest to newest.\n",
    "\n",
    "> Bonus discussion question: does showing the data this way tell the whole story? What other factors could affect the average year the art was created?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Group values by two factors\n",
    "\n",
    "Find how many works of art each artist created using different mediums. Group by artist and medium to create a chart that shows the counts of how many works of art an artist created in a certain medium.\n",
    "\n",
    "for year created for each department (Painting & Sculpture, Drawings & Prints, Film, Fluxus Collection, Media & Performance). Group the data using 'Department,' then show a table with the average 'YearCreated' for each department, sorted from oldest to newest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further resources\n",
    "\n",
    "### Filled version of this notebook\n",
    "\n",
    "[Python Open Labs Week 4 filled notebook](https://colab.research.google.com/github/ncsu-libraries-data-vis/python-open-labs/blob/main/Open_Lab_4_exploratory_analysis_with_pandas/filled_Open_Lab_4_exploratory_analysis_with_pandas.ipynb) - a version of this notebook with all code filled in for the guided activity and exercises.\n",
    "### Learning resources\n",
    "\n",
    "- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/index.html) - a free, online version of Jake VanderPlas' introduction to data science with Python, includes a chapter on data manipulation with pandas.\n",
    "- [Python Programming for Data Science](https://www.tomasbeuzen.com/python-programming-for-data-science/README.html) - a website providing a great overview of conducting data science with Python including pandas.\n",
    "- [Real Python](https://realpython.com/) contains a lot of different tutorials at different levels\n",
    "- [LinkedIn Learning](https://www.lynda.com/Python-training-tutorials/415-0.html) is free with NC State accounts and contains several video series for learning Python\n",
    "- [Dataquest](https://www.dataquest.io/) is a free then paid series of courses with an emphasis on data science\n",
    "\n",
    "### Finding help with pandas\n",
    "\n",
    "The [Pandas website](https://pandas.pydata.org/) and [online documentation](http://pandas.pydata.org/pandas-docs/stable/) are useful resources, and of course the indispensible [Stack Overflow has a \"pandas\" tag](https://stackoverflow.com/questions/tagged/pandas).  There is also a (much younger, much smaller) [sister site dedicated to Data Science questions that has a \"pandas\" tag](https://datascience.stackexchange.com/questions/tagged/pandas) too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Survey\n",
    "Please, spend 1 minute answering these questions that help improve future workshops.\n",
    "\n",
    "https://go.ncsu.edu/dvs-eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "\n",
    "This workshop was created by Claire Cahoon and Walt Gurley, adapted from previous workshop materials by Scott Bailey and Simon Wiles, of Stanford Libraries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
