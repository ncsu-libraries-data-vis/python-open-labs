{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Open Labs: Working with multiple datasets in pandas\n",
    "\n",
    "## Setup\n",
    "\n",
    "With this Google Colaboratory (Colab) notebook open, click the \"Copy to Drive\" button that appears in the menu bar. The notebook will then be attached to your own user account, so you can edit it in any way you like -- you can even take notes directly in the notebook.\n",
    "\n",
    "## Open Labs agenda\n",
    "\n",
    "1. **Guided activity**: One of the instructors will share their screen to work through the guided activity and teach concepts along the way.\n",
    "\n",
    "2. **Open lab time**: After the guided portion of the Open Lab, the rest of the time is for you to ask questions, work collaboratively, or have self-guided practice time. You will have access to instructors and peers for questions and support.\n",
    "\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "By the end of our workshop today, we hope you'll understand basic pandas methods for loading, combining, and preparing different types of datasets for analyses with pandas.\n",
    "\n",
    "## Today's Topics\n",
    "\n",
    "- Editing DataFrame index labels and column headers\n",
    "- Concatenating DataFrames\n",
    "- Merging DataFrames\n",
    "- Removing columns from a DataFrame\n",
    "- Filtering rows in a DataFrame\n",
    "\n",
    "## Questions during the workshop\n",
    "\n",
    "Please feel free to ask questions throughout the workshop.\n",
    "\n",
    "We have a second instructor who will available during the workshop. They will answer as able, and will collect questions with answers that might help everyone to be answered at the end of the workshop.\n",
    "\n",
    "The open lab time is when you will be able to ask more questions and work together on the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided Instruction\n",
    "\n",
    "In this Open Lab we're introducing how to use the pandas library to load, combine, and prepare multiple datasets for analysis.\n",
    "\n",
    "In this section, we will work through examples using data from the [Museum of Modern Art (MoMA) research dataset](https://github.com/MuseumofModernArt/collection) containing records of all of the works that have been cataloged in the database of the MoMA collection.\n",
    "\n",
    "> \"The Museum’s website features 89,695 artworks from 26,494 artists. This research dataset contains 138,151 records, representing all of the works that have been accessioned into MoMA’s collection and cataloged in our database. It includes basic metadata for each work, including title, artist, date made, medium, dimensions, and date acquired by the Museum. Some of these records have incomplete information and are noted as “not Curator Approved.\" - [MoMA Github repository for collection data](https://github.com/MuseumofModernArt/collection)\n",
    "\n",
    "We have split the dataset into several different subsections (paintings, sculptures, photographs, and artist information) and file types to use in activities. We will be referencing the data that we have prepared in our [Github repository for teaching datasets](https://github.com/ncsu-libraries-data-vis/teaching-datasets/tree/main/moma_data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Pandas library as pd (callable in our code as pd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MoMA paintings dataset (CSV file\n",
    "# The file location\n",
    "paintings_file_url = 'https://raw.githubusercontent.com/ncsu-libraries-data-vis/teaching-datasets/main/moma_data/moma_paintings.csv'\n",
    "\n",
    "# Read in the file and print out the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MoMA photographs dataset (Excel file)\n",
    "# The file location\n",
    "photos_file_url = 'https://raw.githubusercontent.com/ncsu-libraries-data-vis/teaching-datasets/main/moma_data/moma_photographs.xlsx'\n",
    "\n",
    "# Read in the file and print out the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MoMA sculptures dataset (JSON file)\n",
    "# The file location\n",
    "sculptures_file_url = 'https://raw.githubusercontent.com/ncsu-libraries-data-vis/teaching-datasets/main/moma_data/moma_sculptures.json'\n",
    "\n",
    "# Read in the file and print out the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset DataFrame index labels\n",
    "\n",
    "The JSON file of sculpture artworks we imported does not include the column `Index`. Instead, these values are used as the index labels. We want this dataset to match the format of our paintings and photographs datasets, so we first need to reset the index of the `sculptures` dataset using the DataFrame method `reset_index()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the sculptures DataFrame index\n",
    "\n",
    "\n",
    "# Print out the resulting dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming column labels\n",
    "\n",
    "When we reset our index a new column with the label `index` was created. Let's change the name of this column to `Index` (with an uppercase \"I\") to match our other datasets using the DataFrame method `rename()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column we created\n",
    "\n",
    "\n",
    "# Print out the first five columns of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate DataFrames\n",
    "\n",
    "We want to be able to work with all of the data we have imported at once, so we need to pull all three DataFrames into one DataFrame. They all have the same column format now, so we can concatenate them based on column name and order (similar to adding them together, one on top of another) using the pandas method `concat()`.\n",
    "\n",
    "We also need to consider the current index labels for each dataset. We will create a new zero-based integer index label for the concatenated dataset by passing the keyword argument `ignore_index=True` into the `concat()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the datasets into one\n",
    "\n",
    "\n",
    "# Print the shape (number of rows and columns) of the full DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join DataFrames on shared column values\n",
    "\n",
    "Our dataset includes a column of unique artist IDs (`ConstituentID`) that identify a specific artist. The MoMA also provides another dataset of artist information in which each row includes specific biographical information about a specific artist:\n",
    "\n",
    "|ConstituentID  |DisplayName    |ArtistBio  |Nationality | ... |\n",
    "|---|---|---|---|---|\n",
    "|1  |Robert Arneson |\"American, 1930–1992\"  |American   | ...   |\n",
    "|2  |Doroteo Arnaiz |\"Spanish, born 1936\"   |Spanish    | ...   |\n",
    "| &#8942; | &#8942; | &#8942; | &#8942; | &#8942; |\n",
    "|133026 |Alfred Tritschler  |\"German, 1905 – 1970\"  |German | ...   |\n",
    "\n",
    "The artists dataset also includes a column of artist IDs in `ConstituentID`. Let's join our DataFrame of MoMA artworks (`moma_art`) with the artists dataset using the shared values of each dataset's `ConsituentID` column using the pandas method `merge()`. The resulting DataFrame will now include artist biographical information with each piece of artwork.\n",
    "\n",
    "We first need to load the artists dataset as a DataFrame. The URL to the dataset is stored in the variable `artists_file_url`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load artists dataset (stored in a CSV file)\n",
    "artists_file_url = 'https://raw.githubusercontent.com/ncsu-libraries-data-vis/teaching-datasets/main/moma_data/moma_artists.csv'\n",
    "\n",
    "\n",
    "# Print the new DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Left join visual example](./left-join.png)\n",
    "\n",
    "We will use a \"left\" join to merge columns from the `artists` DataFrame into the `moma_art` DataFrame based on matching values in each DataFrame's `ConstituentID` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame from a \"left\" join of the full artworks DataFrame\n",
    "# and the artists DataFrame base on the shared column \"ConstituentID\"\n",
    "\n",
    "\n",
    "# Print out the new merged dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing unnecessary columns\n",
    "\n",
    "We can reduce the size of our combined dataset by removing columns that are not important for our analyses. Columns can be \"dropped\" from a DataFrame using the DataFrame method `drop()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the column labels for the full dataset of artworks and artist info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not be using any of the external link resources, so we can remove the columns `URL`, `ThumbnailURL`, and `Wiki QID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove specified columns from the dataset using \"drop()\"\n",
    "\n",
    "\n",
    "# Print out the column labels from the new DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering rows in a DataFrame\n",
    "\n",
    "We can filter rows of a DataFrame using conditional statements to test if values within one or more columns meet the provided criteria. This is helpful if say we want to remove unnecessary rows of data or observe a specific range of data.\n",
    "\n",
    "Let's first demonstrate the structure of writing a conditional statement to test the values of a single column by identifying all artists that were born before the 20th century (`BeginDate < 1900`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which values in the \"BeginDate\" column are less than 1900\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the conditional statement above to filter our entire DataFrame to only return rows with the value `True`, in other words, rows in which the artists who created the artwork was born before 1900.\n",
    "\n",
    "This operation is called **boolean indexing** as we are using the occurrence of `True` values from Series returned by the conditional statement to create a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the final DataFrame to only return rows of artworks whose artist was\n",
    "# born before 1900\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the final DataFrame to only return rows of artworks by Pablo Picasso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering on multiple conditions has a slightly different syntax than a standard Python conditional statement with logical operators (that is, conditional statements using `and`, `or`, or `not`). When filtering a DataFrame using multiple conditional statements use the operators `|` in place of `or`, `&` in place of `and`, and `~` in place of `not`. Additionally, each statement must be surrounded by parentheses to maintain correct order of operation.\n",
    "\n",
    "Let's filter the full MoMA artworks DataFrame to return only artworks by Japanese artists (`Nationality == Japanese`) born in the 20th century or later (`BeginDate >= 1900`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the final DataFrame to only return rows of artworks by Japanese artists\n",
    "# born in the 20th century or later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Open work time\n",
    "\n",
    "You can use this time to ask questions, collaborate, or work on the following exercises (on your own or in a group).\n",
    "\n",
    "For these exercises you will be using two new datasets containing data on MoMA artworks classified as audio and artworks classified as video in addition to the artists dataset already imported (the DataFrame `artists`). These audio and video artwork datasets contain the same columns as the datasets you have been working with.\n",
    "\n",
    "Before starting the exercises you will need to load the new datasets as DataFrames. Both datasets are CSV files and the URL to each file is provided in the variables below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs to the audio and video datasets\n",
    "audios_file_url = 'https://raw.githubusercontent.com/ncsu-libraries-data-vis/teaching-datasets/main/moma_data/moma_audios.csv'\n",
    "videos_file_url = 'https://raw.githubusercontent.com/ncsu-libraries-data-vis/teaching-datasets/main/moma_data/moma_videos.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Concatenate DataFrames\n",
    "\n",
    "Combine the MoMA audio and video datasets along the rows axis (in other words, stack them on top of each other). Make sure the resulting DataFrame contains unique row index labels (*you can test this by printing the output of calling `.loc[0]` on the new DataFrame*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Rename column headers\n",
    "\n",
    "To maintain consistency in the representation of measurement units of artworks, change the label of the column that contains the duration of an artwork, currently labeled as `Duration (sec.)`, to `Duration (s)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Join DataFrames on shared column values\n",
    "\n",
    "Add artist information, contained in the DataFrame `artists`, to the full audio and video artworks dataset. Use a join technique that maintains the original form of the audio and video DataFrame and appends columns from the `artists` DataFrame based on the shared column values in `ConstituentID` contained in each DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Drop columns from DataFrame\n",
    "\n",
    "We won't need to use the references to external content (for example, URL, Wiki QID, etc.). Use the list of columns in the code cell below to remove the columns in this list from the full audio and video DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Filter DataFrame rows using single condition\n",
    "\n",
    "Filter the full audio and video DataFrame to artworks with a duration greater than 60 seconds.\n",
    "\n",
    "*The column `Duration (s)` contains the duration of an artwork in seconds.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the full audio and video artworks DataFrame to return only artworks\n",
    "# with a duration grater than 60 seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Filter DataFrame rows using multiple conditions\n",
    "\n",
    "Filter the full audio and video artworks DataFrame to return only artworks that have not been cataloged and were not created by artists who identify as Male. Remember, logical operators for boolean indexing are `|` for `or`, `&` for `and`, and `~` for `not`.\n",
    "\n",
    "*The column `Cataloged` indicates whether an artwork has or has not been cataloged using the value `Y` to indicated yes and `N` to indicate no.*\n",
    "\n",
    "*The column `Gender` indicates the gender of an artist and includes the values `Male`, `Female`, `Non-binary`, `Non-Binary`, and `NaN`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the full audio and video DataFrame to to return only artworks that\n",
    "# have not been cataloged and were not created by artists who identify as Male \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further resources\n",
    "\n",
    "### Filled version of this notebook\n",
    "\n",
    "[Python Open Labs Week 2 filled notebook](https://colab.research.google.com/github/ncsu-libraries-data-vis/python-open-labs/blob/main/Open_Lab_2_working_with_multiple_datasets_in_pandas/filled_Open_Lab_2_working_with_multiple_datasets_in_pandas.ipynb) - a version of this notebook with all code filled in for the guided activity and exercises.\n",
    "\n",
    "### Learning resources\n",
    "\n",
    "- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/index.html) - a free, online version of Jake VanderPlas' introduction to data science with Python, includes a chapter on data manipulation with pandas.\n",
    "- [Python Programming for Data Science](https://www.tomasbeuzen.com/python-programming-for-data-science/README.html) - a website providing a great overview of conducting data science with Python including pandas.\n",
    "- [Real Python](https://realpython.com/) contains a lot of different tutorials at different levels\n",
    "- [LinkedIn Learning](https://www.lynda.com/Python-training-tutorials/415-0.html) is free with NC State accounts and contains several video series for learning Python\n",
    "- [Dataquest](https://www.dataquest.io/) is a free then paid series of courses with an emphasis on data science\n",
    "\n",
    "### Finding help with pandas\n",
    "\n",
    "The [Pandas website](https://pandas.pydata.org/) and [online documentation](http://pandas.pydata.org/pandas-docs/stable/) are useful resources, and of course the indispensible [Stack Overflow has a \"pandas\" tag](https://stackoverflow.com/questions/tagged/pandas).  There is also a (much younger, much smaller) [sister site dedicated to Data Science questions that has a \"pandas\" tag](https://datascience.stackexchange.com/questions/tagged/pandas) too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAAF-mLyRqeE"
   },
   "source": [
    "## Evaluation Survey\n",
    "Please, spend 1 minute answering these questions that help improve future workshops.\n",
    "\n",
    "[go.ncsu.edu/dvs-eval](https://go.ncsu.edu/dvs-eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6Sj-7OYR5JL"
   },
   "source": [
    "## Credits\n",
    "\n",
    "This workshop was created by Claire Cahoon and Walt Gurley, adapted from previous workshop materials by Scott Bailey and Simon Wiles, of Stanford Libraries."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Python_Open_Labs_Week2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "0bb8fac8a0c82f4f5ccbcc488a26fe869e7789c40997937e38e89b37cd70a2e8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('anaconda3': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
