{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Open Labs: Data wrangling with pandas\n",
    "\n",
    "## Setup\n",
    "\n",
    "With this Google Colaboratory (Colab) notebook open, click the \"Copy to Drive\" button that appears in the menu bar. The notebook will then be attached to your own user account, so you can edit it in any way you like -- you can even take notes directly in the notebook.\n",
    "\n",
    "## Open Labs agenda\n",
    "\n",
    "1. **Guided activity**: One of the instructors will share their screen to work through the guided activity and teach concepts along the way.\n",
    "\n",
    "2. **Open lab time**: After the guided portion of the Open Lab, the rest of the time is for you to ask questions, work collaboratively, or have self-guided practice time. You will have access to instructors and peers for questions and support.\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "By the end of our workshop today, we hope you'll understand basic pandas methods for normalizing values, modifying data, dealing with missing data, and working with strings and dates.\n",
    "\n",
    "## Today's Topics\n",
    "\n",
    "- Replacing values in a DataFrame column\n",
    "- Creating new columns using expressions\n",
    "- Creating new columns with functions\n",
    "- Dealing with missing values\n",
    "- Working with string data\n",
    "- Working with dates\n",
    "\n",
    "## Questions during the workshop\n",
    "\n",
    "Please feel free to ask questions throughout the workshop.\n",
    "\n",
    "We have a second instructor who will available during the workshop. They will answer as able, and will collect questions with answers that might help everyone to be answered at the end of the workshop.\n",
    "\n",
    "The open lab time is when you will be able to ask more questions and work together on the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided Instruction\n",
    "\n",
    "In this Open Lab we're introducing how to use the pandas library to \"wrangle\" data; or clean, manipulate, and prepare datasets for analysis.\n",
    "\n",
    "In this section, we will work through examples using data from the [Museum of Modern Art (MoMA) research dataset](https://github.com/MuseumofModernArt/collection) containing records of all of the works that have been cataloged in the database of the MoMA collection.\n",
    "\n",
    "> \"The Museum’s website features 89,695 artworks from 26,494 artists. This research dataset contains 138,151 records, representing all of the works that have been accessioned into MoMA’s collection and cataloged in our database. It includes basic metadata for each work, including title, artist, date made, medium, dimensions, and date acquired by the Museum. Some of these records have incomplete information and are noted as “not Curator Approved.\" - [MoMA Github repository for collection data](https://github.com/MuseumofModernArt/collection)\n",
    "\n",
    "We have prepared a dataset that consists of a subset of MoMA artworks classified as paintings and their associated artist information to use in the following activities. We will be referencing the data that we have prepared in our [Github repository for teaching datasets](https://github.com/ncsu-libraries-data-vis/teaching-datasets/tree/main/moma_data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Pandas library as pd (callable in our code as pd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MoMA paintings with artist information dataset (CSV file)\n",
    "# The file location\n",
    "file_url = 'https://raw.githubusercontent.com/ncsu-libraries-data-vis/teaching-datasets/main/moma_data/moma_paintings_full.csv'\n",
    "\n",
    "# Read in the file and print out the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe a summary of the DataFrame columns using the DataFrame method info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing values in a column\n",
    "\n",
    "We can replace values in a column by first accessing that column and using the Series method `replace()` (*remember accessing one column from a DataFrame returns a pandas Series*). The `replace()` method can accept a dictionary of items in which the dictionary keys are the values to be replaced and the dictionary values are the new values to be inserted.\n",
    "\n",
    "We will demonstrate this method by replacing the values `Y` and `N` in the `Cataloged` column to the more explicit values `Yes` and `No`, respectively. Also, we will edit the DataFrame directly by including the keyword argument `inplace=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the unique values contained in the \"Cataloged\" column using the\n",
    "# DataFrame method unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the values \"Y\" and \"N\" in the \"Cataloged\" column with \"Yes\" and \"No\"\n",
    "\n",
    "\n",
    "# Print out the unique values of the \"Cataloged\" column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new column using an expression\n",
    "\n",
    "We can create new columns of data on an existing DataFrame and assign values calculated from existing columns of data. This is done by first calling the index of the new column (for example, `df['NEW_COLUMN_NAME']`) and assigning the new column the results of some expression that can include existing columns of data from the DataFrame.\n",
    "\n",
    "We will create a new column named `Area (cm^2)` that contains the centimeter squared area of a painting based on the values provided in the columns `Width (cm)` and `Height (cm)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column \"Area (cm^2)\" containing the size of a painting based\n",
    "# on the width and height value of the painting\n",
    "\n",
    "\n",
    "# Print out the full DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new column using apply\n",
    "\n",
    "Sometimes we need to create new data using more complex methods than a simple expression. We will create a new column named `OilPainting` to identify all painting that contain the word \"oil\" in their medium description (contained in the column `medium`). This cannot be reliably accomplished without doing some advanced manipulation of the medium description.\n",
    "\n",
    "We will use the Series method `apply()` to call the function `is_oil_based_painting`, which contains the necessary code to produce the desired results, on the column `Medium`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return whether a painting is oil-based (Yes) or not (No) based on the\n",
    "# occurrence of the word \"oil\" in the artwork medium description\n",
    "def is_oil_based_painting(medium):\n",
    "    # Test if value is a string (can't apply string methods on NaNs)\n",
    "    if type(medium) == str:\n",
    "        # Create a list of lowercase words, commas removed, from description\n",
    "        description = medium.lower().replace(',', '').split(' ')\n",
    "        # Test if \"oil\" is in list\n",
    "        if 'oil' in description:\n",
    "            return 'Yes'\n",
    "        return 'No'\n",
    "\n",
    "# Use the Series method apply to call the \"is_oil_based_painting\" function on\n",
    "# the column \"Medium\"\n",
    "\n",
    "\n",
    "# Print out the resulting DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing missing data\n",
    "\n",
    "The MoMA paintings dataset contains many missing values. Missing values in a pandas are typically represented as `NaN`. We can handle missing values in several ways, removing all rows or columns containing one or more `NaN`s, removing rows or columns based on the occurrence of `NaN`s within specific rows or columns, or filling in `NaN` values with another value.\n",
    "\n",
    "We want to work with paintings that have artist information associated with them. A painting that does not have artist information can be identified by a value of `NaN` in the column `ArtistBio`. We will create a subset of the full `paintings` DataFrame by removing all rows that contain `NaN` in the `ArtistBio` column using the DataFrame method `dropna()` and specifying a column `subset` over which to look for `NaN`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame containing only paintings that include artist\n",
    "# information by removing rows that include \"NaN\" in the column \"ArtistBio\"\n",
    "# using the DataFrame method dropna()\n",
    "\n",
    "\n",
    "# Print out the resulting DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with string data\n",
    "\n",
    "A lot of the MoMA data consists of strings. There is currently no string data type in pandas, strings are represented by the pandas *object* data type. We can apply string methods to pandas arrays by accessing the `.str` attribute of the array. For example, we can access the string values of the `Artists` column in the full dataset by calling `moma_data[Artists].str`.\n",
    "\n",
    "If we look at the `Gender` column, we see that the gender types are not represented in a normalized way (for example, female is represented in some cases by the value `Female` and in other cases `female`). We will use the `lower()` string method to produce a lowercase string for all values in the `Gender` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the unique values contained in the \"Gender\" column using the\n",
    "# DataFrame method unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign the column \"Gender\" with the results of calling the string method\n",
    "# lower() on the values in the \"Gender\" column\n",
    "\n",
    "\n",
    "# Print the unique values contained in the \"Gender\" column using the\n",
    "# DataFrame method unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Datetime data\n",
    "\n",
    "Our MoMA dataset contains some columns of data that represent date values (for example, `DateAcquired`, `BeginDate`, `EndDate`). Currently, each of these columns is recognized as strings (the pandas object datatype). If we look at the `DateAcquired` column we see that it contains the date that an artwork was acquired by the museum in the form `YYYY-MM-DD` (for example, `1964-10-06`). If we wanted to filter these values by year, we would not be able to do this in their current string format.\n",
    "\n",
    "We can convert the values in the `DateAcquired` column to a pandas Datetime data type to use them as a datetime format, a format for a value that contains date and time information, using the pandas method `to_datetime()` on the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign the string values in the column \"DateAcquired\" as Datetime values\n",
    "# using the pandas method to_datetime()\n",
    "\n",
    "\n",
    "# Print out the new \"DateAcquired\" column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now filter the DataFrame by date, based on the values in the `DataAcquired` column. Let's filter the cleaned paintings DataFrame to only include paintings acquired before 1960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the cleaned paintings DataFrame to only include paintings acquired\n",
    "# before 1960\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Open work time\n",
    "\n",
    "You can use this time to ask questions, collaborate, or work on the following exercises (on your own or in a group).\n",
    "\n",
    "For these exercises you will be using a dataset that consists of MoMA artworks classified as photographs and each photograph's associated artist information. This dataset has the same columns and column names as the original paintings dataset from the guided activity.\n",
    "\n",
    "Before starting the exercises you will need to load the new dataset as DataFrames. It is available as a CSV file and the URL to the file is provided in the variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs to the photographs dataset\n",
    "photos_file_url = 'https://raw.githubusercontent.com/ncsu-libraries-data-vis/teaching-datasets/main/moma_data/moma_photographs_full.csv'\n",
    "\n",
    "# Import the photographs dataset as a DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Rename column values\n",
    "\n",
    "In the photographs dataset, replace the values in the column `Cataloged`. Replace all occurrences of the value `Y` with the value `Yes` and all occurrences of the value `N` with the value `No`. Overwrite the existing values with the new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the values \"Y\" and \"N\" in the \"Cataloged\" column with \"Yes\" and \"No\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Create a new column using an expression\n",
    "\n",
    "Create a new column, `Aspect`, that contains the aspect ratio (width / height) of a photograph using the values in the `Width (cm)` and `Height (cm)` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named \"Aspect\" that contains the aspect ratio of a\n",
    "# photograph based on the values in columns \"Width (cm)\" and \"Height (cm)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Create a new column using apply\n",
    "\n",
    "Use the values in the column `BeginDate` to create a new column, `CenturyBorn`, in the photos DataFrame that indicates the century in which an artist was born using a function that returns:\n",
    "- `18th` if the artist was born between 1700-1799,\n",
    "- `19th` if the artist was born between 1800-1899,\n",
    "- `20th` if the artist was born between 1900-1999,\n",
    "- `21st` if the artist was born between 2000-present, and\n",
    "- `unknown` otherwise.\n",
    "\n",
    "The `BeginDate` column contains the year in which an artist was born. Unknown artist birth years are identified with the value `0`. The function `century_born()` has been provided for you to use with the apply method, but you can create your own for extra practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the century in which an artist was born given their birth year\n",
    "def century_born(year):\n",
    "    if year > 1999:\n",
    "        return '21st'\n",
    "    elif year > 1899:\n",
    "        return '20th'\n",
    "    elif year > 1799:\n",
    "        return '19th'\n",
    "    elif year > 1699:\n",
    "        return '18th'\n",
    "    return 'unknown'\n",
    "\n",
    "# Create a new column named \"CenturyBorn\" that contains the century in which an\n",
    "# artist was born using data from the column \"BeginDate\" and the function\n",
    "# century_born\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Remove missing values\n",
    "\n",
    "We are only interested in artworks that have a defined width and height. Use the column `Aspect` to remove any rows from the dataset that do not have a defined aspect ratio (in other words, values that are `NaN`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows from the dataset that have an \"NaN\" value in the \"Aspect\" column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Use a string method to normalize data\n",
    "\n",
    "Normalize the values in the column `Gender` by applying the string method `title()` to convert all strings to title case (for example, convert `male` to `Male` and `female` to `Female`). Print out the unique values of this column after performing the operation to ensure only three values are present (`Male`, `Female`, and `nan`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the string values in the \"Gender\" column to title case (each word\n",
    "# beginning with a capital letter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Convert string data to Datetime\n",
    "\n",
    "Convert the string data contained in the column `DateAcquired` to Datetime data type. Reassign the new Datetime values to the existing `DateAcquired` column and then use this column to filter the DataFrame for items acquired in or after the year 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the string data in the column \"DateAcquired\" to a Datetime data type\n",
    "\n",
    "\n",
    "# Use the updated column to filter the DataFrame to photos acquired in or after\n",
    "# the year 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further resources\n",
    "\n",
    "### Filled version of this notebook\n",
    "\n",
    "[Python Open Labs Week 3 filled notebook](https://colab.research.google.com/github/ncsu-libraries-data-vis/python-open-labs/blob/main/Open_Lab_3_data_wrangling_with_pandas/filled_Open_Lab_3_data_wrangling_with_pandas.ipynb) - a version of this notebook with all code filled in for the guided activity and exercises.\n",
    "\n",
    "### Learning resources\n",
    "\n",
    "- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/index.html) - a free, online version of Jake VanderPlas' introduction to data science with Python, includes a chapter on data manipulation with pandas.\n",
    "- [Python Programming for Data Science](https://www.tomasbeuzen.com/python-programming-for-data-science/README.html) - a website providing a great overview of conducting data science with Python including pandas.\n",
    "- [Real Python](https://realpython.com/) contains a lot of different tutorials at different levels\n",
    "- [LinkedIn Learning](https://www.lynda.com/Python-training-tutorials/415-0.html) is free with NC State accounts and contains several video series for learning Python\n",
    "- [Dataquest](https://www.dataquest.io/) is a free then paid series of courses with an emphasis on data science\n",
    "\n",
    "### Finding help with pandas\n",
    "\n",
    "The [Pandas website](https://pandas.pydata.org/) and [online documentation](http://pandas.pydata.org/pandas-docs/stable/) are useful resources, and of course the indispensible [Stack Overflow has a \"pandas\" tag](https://stackoverflow.com/questions/tagged/pandas).  There is also a (much younger, much smaller) [sister site dedicated to Data Science questions that has a \"pandas\" tag](https://datascience.stackexchange.com/questions/tagged/pandas) too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAAF-mLyRqeE"
   },
   "source": [
    "## Evaluation Survey\n",
    "Please, spend 1 minute answering these questions that help improve future workshops.\n",
    "\n",
    "[go.ncsu.edu/dvs-eval](https://go.ncsu.edu/dvs-eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6Sj-7OYR5JL"
   },
   "source": [
    "## Credits\n",
    "\n",
    "This workshop was created by Claire Cahoon and Walt Gurley, adapted from previous workshop materials by Scott Bailey and Simon Wiles, of Stanford Libraries."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0bb8fac8a0c82f4f5ccbcc488a26fe869e7789c40997937e38e89b37cd70a2e8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
